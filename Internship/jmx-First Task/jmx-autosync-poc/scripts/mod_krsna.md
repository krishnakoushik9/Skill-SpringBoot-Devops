# ğŸ§ª JMX Unit Test Generator - mod_krsna

> **Author:** Krishna (mod_krsna)  
> **Created:** January 2026  
> **Purpose:** Automatically generate JMeter unit test files from OpenAPI specifications

---

## ğŸ¯ What is this?

`jmx_unit.py` is a Python script that automatically converts your OpenAPI/Swagger API specifications into **JMeter unit test files** (`.jmx`). These unit tests validate that each API endpoint works correctly in isolation.

---

## ğŸ”„ How it works

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   OpenAPI Spec      â”‚  â†’   â”‚   jmx_unit.py    â”‚  â†’   â”‚  Unit Test JMX     â”‚
â”‚  (user-service.yaml)â”‚      â”‚   (Parser +      â”‚      â”‚ (user-service-     â”‚
â”‚                     â”‚      â”‚    Generator)    â”‚      â”‚      unit.jmx)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### The Flow:

1. **Parse** - Reads your OpenAPI YAML/JSON specification
2. **Extract** - Identifies all API endpoints (paths, methods, parameters, request bodies)
3. **Generate** - Creates JMeter-compatible XML with:
   - One thread group per endpoint (isolated testing)
   - HTTP samplers with populated request data
   - Status code assertions
   - Response time assertions
   - JSON format validation
4. **Output** - Saves as `{service}-unit.jmx` in the `unit-tests/` folder

---

## ğŸ“Š Unit Tests vs Performance Tests

| Aspect | Performance Tests | Unit Tests |
|--------|-------------------|------------|
| **File** | `jmx_generator.py` | `jmx_unit.py` |
| **Output** | `performance-tests/` | `unit-tests/` |
| **Threads** | 10+ (concurrent load) | 1 (isolated) |
| **Duration** | 5+ minutes | Instant |
| **Purpose** | Load testing | Functional validation |
| **Think Time** | Yes (simulates users) | No (fast execution) |

---

## ğŸš€ Quick Start

### Generate all unit tests:
```bash
cd /path/to/jmx-autosync-poc
python scripts/jmx_unit.py --spec-dir api-specs --output-dir unit-tests
```

### Generate for a single spec:
```bash
python scripts/jmx_unit.py --spec api-specs/user-service.yaml --output unit-tests/user-service-unit.jmx
```

### Watch mode (auto-regenerate on changes):
```bash
python scripts/jmx_unit.py --spec-dir api-specs --output-dir unit-tests --watch
```

### With debug mode:
```bash
python scripts/jmx_unit.py --spec-dir api-specs --output-dir unit-tests --debug
```

---

## âš™ï¸ CLI Options

| Option | Short | Description | Default |
|--------|-------|-------------|---------|
| `--spec` | `-s` | Single OpenAPI spec file | - |
| `--spec-dir` | `-d` | Directory with specs | - |
| `--output` | `-o` | Output JMX file path | `{spec}-unit.jmx` |
| `--output-dir` | - | Output directory | `unit-tests` |
| `--watch` | `-w` | Watch for changes | `false` |
| `--interval` | `-i` | Watch interval (seconds) | `5` |
| `--max-response-time` | - | Max response time (ms) | `5000` |
| `--debug` | - | Include debug samplers | `false` |
| `--config` | `-c` | Config file path | - |

---

## ğŸ“ Generated Files

After running the script, your project structure looks like:

```
jmx-autosync-poc/
â”œâ”€â”€ api-specs/
â”‚   â”œâ”€â”€ user-service.yaml
â”‚   â”œâ”€â”€ order-service.yaml
â”‚   â””â”€â”€ ...
â”œâ”€â”€ performance-tests/          â† Generated by jmx_generator.py
â”‚   â”œâ”€â”€ user-service.jmx
â”‚   â””â”€â”€ ...
â”œâ”€â”€ unit-tests/                 â† Generated by jmx_unit.py
â”‚   â”œâ”€â”€ user-service-unit.jmx
â”‚   â”œâ”€â”€ order-service-unit.jmx
â”‚   â””â”€â”€ ...
â””â”€â”€ scripts/
    â”œâ”€â”€ jmx_generator.py
    â”œâ”€â”€ jmx_unit.py
    â””â”€â”€ mod_krsna.md            â† You are here!
```

---

## ğŸ§© What's in the Generated JMX?

Each unit test JMX file contains:

- **Unit Test Variables** - Server, port, protocol, auth token
- **HTTP Request Defaults** - Common settings for all requests  
- **Header Manager** - Content-Type, Accept, Authorization
- **Thread Groups** - One per endpoint for isolation
- **HTTP Samplers** - Actual API requests with sample data
- **Assertions**:
  - Status Code Assertion (200, 201, etc.)
  - Response Time Assertion (< 5 seconds default)
  - JSON Response Assertion (valid JSON)
- **Listeners**:
  - View Results Tree
  - Assertion Results
  - Simple Data Writer

---

## ğŸƒ Running the Tests

### With JMeter GUI:
```bash
jmeter -t unit-tests/user-service-unit.jmx
```

### Headless (CLI):
```bash
jmeter -n -t unit-tests/user-service-unit.jmx -l results.jtl
```

### View results:
The results are saved to `unit-test-results.jtl` by default.

---

## ğŸ’¡ Tips

1. **Update AUTH_TOKEN** - Set your actual token:
   ```bash
   jmeter -Jauth.token=your_actual_token -t test.jmx
   ```

2. **Customize timeouts** - Use `--max-response-time 10000` for slow APIs

3. **Debug issues** - Use `--debug` flag to include debug post-processors

4. **Automate** - Use `--watch` during development for auto-sync

---

## ğŸ”§ Requirements

- Python 3.7+
- PyYAML (`pip install pyyaml`)
- JMeter 5.x (for running tests)

---

**Happy Testing! ğŸ‰**
